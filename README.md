# Weather Data Engineering Pipeline

## ğŸ“Œ Overview
This project is an end-to-end data engineering pipeline built to strengthen core data engineering fundamentals.

The pipeline ingests weather data from a public REST API, transforms it using pure Python, loads it into PostgreSQL, and orchestrates the workflow using Apache Airflow. The entire project is developed and executed inside GitHub Codespaces.

## ğŸ—ï¸ Architecture
- Data Source: Public Weather REST API
- Ingestion: Python (`requests`)
- Transformation: Pure Python
- Storage: PostgreSQL
- Orchestration: Apache Airflow
- Development Environment: GitHub Codespaces
- Containerization: Docker

## ğŸ”„ Pipeline Flow
1. Extract weather data from API
2. Store raw JSON data
3. Transform and clean data using Python
4. Load structured data into PostgreSQL
5. Run data quality checks
6. (Optional) Visualize data using Streamlit

## ğŸ§° Tech Stack
- Python
- Apache Airflow
- PostgreSQL
- Docker & Docker Compose
- GitHub Codespaces

## ğŸ¯ Learning Objectives
- Understand end-to-end data pipeline design
- Strengthen Python fundamentals for data engineering
- Learn workflow orchestration using Airflow
- Implement basic data quality checks
- Build production-style data pipelines

## ğŸš€ Getting Started
Instructions will be added as the project evolves.

## ğŸ“Œ Status
ğŸš§ Project under active development. Learning in public.
